{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Połączenie z google drive"
      ],
      "metadata": {
        "id": "EzSgv5UCdo4E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UmMqxbadZ2m",
        "outputId": "ebaccc41-ef45-452c-f539-7dce7e15d8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Niezbędne importy"
      ],
      "metadata": {
        "id": "lQEbJKN8Aau_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import adjusted_rand_score, davies_bouldin_score\n",
        "from scipy.spatial.distance import cdist"
      ],
      "metadata": {
        "id": "dv8ZzghCiTCC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wczytanie danych"
      ],
      "metadata": {
        "id": "fJdriab5Nd_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_path = '/content/drive/My Drive/data_sety/normalized_word2vec_embeddings.csv'\n",
        "data_embeddings = pd.read_csv(embeddings_path)\n",
        "\n",
        "original_data_path = '/content/drive/My Drive/data_sety/ready_data_set.csv'\n",
        "original_data = pd.read_csv(original_data_path)\n",
        "labels_true = original_data['label']\n"
      ],
      "metadata": {
        "id": "8AWu8X1r-o0g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funckja oblicająca indeks dunn"
      ],
      "metadata": {
        "id": "aOfBOG-fXVBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dunn_index(X, labels):\n",
        "    distances = cdist(X, X, 'euclidean') # Obliczenie odleŋłości między wszystkimi punktami i zapisanie ich w macierzy\n",
        "    unique_clusters = np.unique(labels) # Identyfikacja unikalnych klastrów.\n",
        "\n",
        "    # Inicjalizacja list dla odległości między klastrami i średnic klastrów\n",
        "    inter_cluster_distances = []\n",
        "    intra_cluster_diameters = []\n",
        "\n",
        "    # Obliczanie odległości między klastrami i średnic klastrów\n",
        "    for i in unique_clusters:\n",
        "        for j in unique_clusters:\n",
        "            if i != j:\n",
        "                inter_cluster_distances.append(np.min(distances[labels == i][:, labels == j]))\n",
        "        intra_cluster_diameters.append(np.max(distances[labels == i][:, labels == i]))\n",
        "\n",
        "    # Zwrócenie indeksu Dunn. Jest on stosunkiem najmniejszej odległości między klastrami do największej średnicy klastra.\n",
        "    return np.min(inter_cluster_distances) / np.max(intra_cluster_diameters)"
      ],
      "metadata": {
        "id": "JGdCBtp-XXMQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przygotowanie df do zbierania wyników i zklastrowanych danych"
      ],
      "metadata": {
        "id": "tDHUVQcGBG4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame()\n",
        "results_list = []"
      ],
      "metadata": {
        "id": "DB04KGDFBJUT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores_test = []\n",
        "db_scores_test = []\n",
        "ari_scores_test = []\n",
        "dunn_scores_test = []"
      ],
      "metadata": {
        "id": "_dLw31XUE4PE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores_train = []\n",
        "db_scores_train = []\n",
        "ari_scores_train = []\n",
        "dunn_scores_train = []"
      ],
      "metadata": {
        "id": "wAW2rYdCJfaA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Klasteryzacja z wykorzystaniem 5-krotnej walidacji krzyżowej"
      ],
      "metadata": {
        "id": "BaBbBn94AptU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_embeddings_array = data_embeddings.to_numpy()\n",
        "\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "fold_number = 0\n",
        "for train_index, test_index in kf.split(data_embeddings_array):\n",
        "    fold_number += 1\n",
        "    X_train, X_test = data_embeddings.iloc[train_index], data_embeddings.iloc[test_index]\n",
        "    y_train, y_test = labels_true[train_index], labels_true[test_index]\n",
        "\n",
        "     # Klasteryzacja za pomocą K-means\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42) # Inicjalizacja modelu klasteryzatora\n",
        "    kmeans.fit(X_train) # Trenowanie klasteryzatora na danych treningowych\n",
        "\n",
        "    labels_pred_train = kmeans.predict(X_train) # Przypisywanie danych treningowych do jednego z dwóch klastrów na podstwie wyuczonych centrów klastrów\n",
        "    labels_pred_test = kmeans.predict(X_test) # Przypisywanie danych testowych do jednego z dwóch klastrów na podstwie wyuczonych centrów klastrów\n",
        "\n",
        "    # Obliczanie metryk dla danych testowych\n",
        "    silhouette_test = silhouette_score(X_test, labels_pred_test)\n",
        "    db_index_test = davies_bouldin_score(X_test, labels_pred_test)\n",
        "    ari_test = adjusted_rand_score(y_test, labels_pred_test)\n",
        "    dunn_test = dunn_index(X_test, labels_pred_test)\n",
        "\n",
        "    # Obliczanie metryk dla danych treningowych\n",
        "    silhouette_train = silhouette_score(X_train, labels_pred_train)\n",
        "    db_index_train = davies_bouldin_score(X_train, labels_pred_train)\n",
        "    ari_train = adjusted_rand_score(y_train, labels_pred_train)\n",
        "    dunn_train = dunn_index(X_train, labels_pred_train)\n",
        "\n",
        "    # Dodanie wyników do listy wyników w celu obliczenia średniej na koniec dla danych testowych\n",
        "    silhouette_scores_test.append(silhouette_test)\n",
        "    db_scores_test.append(db_index_test)\n",
        "    ari_scores_test.append(ari_test)\n",
        "    dunn_scores_test.append(dunn_test)\n",
        "\n",
        "    # Dodanie wyników do listy wyników w celu obliczenia średniej na koniec dla danych treningowych\n",
        "    silhouette_scores_train.append(silhouette_train)\n",
        "    db_scores_train.append(db_index_train)\n",
        "    ari_scores_train.append(ari_train)\n",
        "    dunn_scores_train.append(dunn_train)\n",
        "\n",
        "    results_list.append({\n",
        "        'Fold': fold_number,\n",
        "        'Silhouette Score Test': silhouette_test,\n",
        "        'DB score Test': db_index_test,\n",
        "        'ARI Score Test': ari_test,\n",
        "        'Dunn Index Test': dunn_test,\n",
        "        'Silhouette Score Train': silhouette_train,\n",
        "        'DB score Train': db_index_train,\n",
        "        'ARI Score Train': ari_train,\n",
        "        'Dunn Index Train': dunn_train\n",
        "    })\n",
        "\n",
        "    # Wyświetlenie wyników częściowych dla danego etapu\n",
        "    print(\"Fold \" + str(fold_number) + \" Silhouette Score Test: \" + str(silhouette_test) + \" DB Score Test: \" + str(db_index_test) + \" ARI Score Test: \" + str(ari_test) + \" Dunn Index Test: \" + str(dunn_test) + \" Silhouette Score Train: \" + str(silhouette_train) +  \" DB Score Train: \" + str(db_index_train) + \" ARI Score Train: \" + str(ari_train) + \" Dunn Index Train: \" + str(dunn_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk9hI9Zp-2mw",
        "outputId": "153bddce-a95c-4123-847d-008c00cb4991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyświeylenie podsumowania"
      ],
      "metadata": {
        "id": "WBYBOejcU1g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_silhouette_test = np.mean(silhouette_scores_test)\n",
        "average_db_test = np.mean(db_scores_test)\n",
        "average_ari_test = np.mean(ari_scores_test)\n",
        "average_dunn_test = np.mean(dunn_scores_test)\n",
        "\n",
        "average_silhouette_train = np.mean(silhouette_scores_train)\n",
        "average_db_train = np.mean(db_scores_train)\n",
        "average_ari_train = np.mean(ari_scores_train)\n",
        "average_dunn_train = np.mean(dunn_scores_train)\n",
        "\n",
        "print(\"Average Silhouette Score Test:\", average_silhouette_test)\n",
        "print(\"Average Davies-Bouldin Score Test:\", average_db_test)\n",
        "print(\"Average Adjusted Rand Index Test:\", average_ari_test)\n",
        "print(\"Average Dunn Index Test:\", average_dunn_test)\n",
        "\n",
        "print(\"Average Silhouette Score Train:\", average_silhouette_train)\n",
        "print(\"Average Davies-Bouldin Score Train:\", average_db_train)\n",
        "print(\"Average Adjusted Rand Index Train:\", average_ari_train)\n",
        "print(\"Average Dunn Index Train:\", average_dunn_train)"
      ],
      "metadata": {
        "id": "SJCJdswY-5oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zapisanie wyników"
      ],
      "metadata": {
        "id": "THIOLpngBqoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_file_path = '/content/drive/My Drive/data_sety/word2vec_kmeans_kfold_clustering_metrics.csv'\n",
        "\n",
        "results_df = pd.DataFrame(results_list)\n",
        "results_df.to_csv(results_file_path, index=False)"
      ],
      "metadata": {
        "id": "iaTS_qKkBsgL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}