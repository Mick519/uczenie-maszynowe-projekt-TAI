{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Wczytanie zbioru danych"
      ],
      "metadata": {
        "id": "AnfwOByQUe5e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOGIPhgAUUo6",
        "outputId": "5743e392-368c-41ac-f792-f861d4ccb430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/My Drive/data_sety/ready_data_set.csv'\n",
        "data_set = pd.read_csv(file_path)\n",
        "print(data_set.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoKVp25tUnHM",
        "outputId": "f3d56502-a735-47d1-9aeb-6fc5ca89031d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                               text  \\\n",
            "0      1  ounce feather bowl hummingbird opec moment ala...   \n",
            "1      1  wulvob get your medircations online qnb ikud v...   \n",
            "2      0   computer connection from cnn com wednesday es...   \n",
            "3      1  university degree obtain a prosperous future m...   \n",
            "4      0  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                       filtered_text  \\\n",
            "0  ounce feather bowl hummingbird opec moment ala...   \n",
            "1  wulvob get your medircations online qnb ikud v...   \n",
            "2   computer connection from cnn com wednesday es...   \n",
            "3  university degree obtain a prosperous future m...   \n",
            "4  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                     normalized_text  \\\n",
            "0  ounce feather bowl hummingbird opec moment ala...   \n",
            "1  wulvob get your medircations online qnb ikud v...   \n",
            "2   computer connection from cnn com wednesday es...   \n",
            "3  university degree obtain a prosperous future m...   \n",
            "4  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                      tokenized_text  \\\n",
            "0  ['ounce', 'feather', 'bowl', 'hummingbird', 'o...   \n",
            "1  ['wulvob', 'get', 'your', 'medircations', 'onl...   \n",
            "2  ['computer', 'connection', 'from', 'cnn', 'com...   \n",
            "3  ['university', 'degree', 'obtain', 'a', 'prosp...   \n",
            "4  ['thanks', 'for', 'all', 'your', 'answers', 'g...   \n",
            "\n",
            "                                     filtered_tokens  \\\n",
            "0  ['ounce', 'feather', 'bowl', 'hummingbird', 'o...   \n",
            "1  ['wulvob', 'get', 'medircations', 'online', 'q...   \n",
            "2  ['computer', 'connection', 'cnn', 'com', 'wedn...   \n",
            "3  ['university', 'degree', 'obtain', 'prosperous...   \n",
            "4  ['thanks', 'answers', 'guys', 'know', 'checked...   \n",
            "\n",
            "                                     lemmatized_text  \n",
            "0  ['ounce', 'feather', 'bowl', 'hummingbird', 'o...  \n",
            "1  ['wulvob', 'get', 'medircation', 'online', 'qn...  \n",
            "2  ['computer', 'connection', 'cnn', 'com', 'wedn...  \n",
            "3  ['university', 'degree', 'obtain', 'prosperous...  \n",
            "4  ['thank', 'answer', 'guy', 'know', 'check', 'r...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zamiana ciągów znaków na listę słów"
      ],
      "metadata": {
        "id": "KmjwHIGFUpdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "data_set['lemmatized_text'] = data_set['lemmatized_text'].apply(ast.literal_eval)"
      ],
      "metadata": {
        "id": "MvVjoz9BUqF9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_set.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-aw8-OuUsl6",
        "outputId": "8322f80e-fa7e-4125-d91c-d6809ab43ecc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                               text  \\\n",
            "0      1  ounce feather bowl hummingbird opec moment ala...   \n",
            "1      1  wulvob get your medircations online qnb ikud v...   \n",
            "2      0   computer connection from cnn com wednesday es...   \n",
            "3      1  university degree obtain a prosperous future m...   \n",
            "4      0  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                       filtered_text  \\\n",
            "0  ounce feather bowl hummingbird opec moment ala...   \n",
            "1  wulvob get your medircations online qnb ikud v...   \n",
            "2   computer connection from cnn com wednesday es...   \n",
            "3  university degree obtain a prosperous future m...   \n",
            "4  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                     normalized_text  \\\n",
            "0  ounce feather bowl hummingbird opec moment ala...   \n",
            "1  wulvob get your medircations online qnb ikud v...   \n",
            "2   computer connection from cnn com wednesday es...   \n",
            "3  university degree obtain a prosperous future m...   \n",
            "4  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                      tokenized_text  \\\n",
            "0  ['ounce', 'feather', 'bowl', 'hummingbird', 'o...   \n",
            "1  ['wulvob', 'get', 'your', 'medircations', 'onl...   \n",
            "2  ['computer', 'connection', 'from', 'cnn', 'com...   \n",
            "3  ['university', 'degree', 'obtain', 'a', 'prosp...   \n",
            "4  ['thanks', 'for', 'all', 'your', 'answers', 'g...   \n",
            "\n",
            "                                     filtered_tokens  \\\n",
            "0  ['ounce', 'feather', 'bowl', 'hummingbird', 'o...   \n",
            "1  ['wulvob', 'get', 'medircations', 'online', 'q...   \n",
            "2  ['computer', 'connection', 'cnn', 'com', 'wedn...   \n",
            "3  ['university', 'degree', 'obtain', 'prosperous...   \n",
            "4  ['thanks', 'answers', 'guys', 'know', 'checked...   \n",
            "\n",
            "                                     lemmatized_text  \n",
            "0  [ounce, feather, bowl, hummingbird, opec, mome...  \n",
            "1  [wulvob, get, medircation, online, qnb, ikud, ...  \n",
            "2  [computer, connection, cnn, com, wednesday, es...  \n",
            "3  [university, degree, obtain, prosperous, futur...  \n",
            "4  [thank, answer, guy, know, check, rsync, manua...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trenowanie modelu FastText. sentences - dane do treningu, vector_size - rozmiar wektora cech (wymiarów) dla każdego słowa, window - maksymalna odległość między aktualnym słowem a przewidywanym w kontekście, min_count - minimalna liczba wystąpień słowa w dokumencie, aby było ono uwzględnione w treningu, workers - liczba wątków roboczych do trenowania modelu"
      ],
      "metadata": {
        "id": "leVZP2R3Vrzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "model = FastText(sentences=data_set['lemmatized_text'], vector_size=100, window=5, min_count=1, workers=4)\n"
      ],
      "metadata": {
        "id": "89sgXIg_VsQS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zapisanie modelu w folderze"
      ],
      "metadata": {
        "id": "TnZ8_kNcWocI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/My Drive/data_sety/word_models/fasttext_model.model'\n",
        "model.save(model_path)\n"
      ],
      "metadata": {
        "id": "8g_WjYpGWpHT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Osadzanie tekstów w całym zbiorze danych"
      ],
      "metadata": {
        "id": "i_VZRBmFWxMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def document_fasttext_embedding(doc, model):\n",
        "    vectors = [model.wv[word] for word in doc if word in model.wv]\n",
        "\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "fasttext_embeddings = np.array([document_fasttext_embedding(doc, model) for doc in data_set['lemmatized_text']])\n"
      ],
      "metadata": {
        "id": "keiD3_IhWxxQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizacja wektorów osadzeń do normy euklidesowej - Dzięki temu różnice w długości wektorów nie wpłyną na wyniki algorytmów klasteryzacji\n",
        "\n",
        "Po normalizacji, punkty są skalowane w taki sposób, by ich odległość od początku układu współrzędnych wynosiła 1."
      ],
      "metadata": {
        "id": "HgevRdjdW3UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "normalized_embeddings = normalize(fasttext_embeddings, norm='l2', axis=1)\n",
        "\n",
        "fasttext_embeddings_df = pd.DataFrame(normalized_embeddings)\n"
      ],
      "metadata": {
        "id": "FFtQBVepW4BM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zapisanie zbioru gotowego do klasteryzacji"
      ],
      "metadata": {
        "id": "IQ3aVevTW_Oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_embeddings_df.to_csv('/content/drive/My Drive/data_sety/normalized_fasttext_embeddings.csv', index=False)\n"
      ],
      "metadata": {
        "id": "YH5awXtZXEZV"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}