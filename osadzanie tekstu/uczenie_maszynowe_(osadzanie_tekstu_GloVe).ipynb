{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Wczytanie zbioru danych"
      ],
      "metadata": {
        "id": "vGyEmakvFfHy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y4kUxJIlbwhz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccff060f-009e-41a5-978a-9100ac80b812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/My Drive/data_sety/ready_data_set.csv'\n",
        "data_set = pd.read_csv(file_path)\n",
        "print(data_set.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddj7NGVhF0of",
        "outputId": "24fb67e2-ad81-4748-a022-91413f6d0b42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                               text  \\\n",
            "0      1  ounce feather bowl hummingbird opec moment ala...   \n",
            "1      1  wulvob get your medircations online qnb ikud v...   \n",
            "2      0   computer connection from cnn com wednesday es...   \n",
            "3      1  university degree obtain a prosperous future m...   \n",
            "4      0  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                       filtered_text  \\\n",
            "0  ounce feather bowl hummingbird opec moment ala...   \n",
            "1  wulvob get your medircations online qnb ikud v...   \n",
            "2   computer connection from cnn com wednesday es...   \n",
            "3  university degree obtain a prosperous future m...   \n",
            "4  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                     normalized_text  \\\n",
            "0  ounce feather bowl hummingbird opec moment ala...   \n",
            "1  wulvob get your medircations online qnb ikud v...   \n",
            "2   computer connection from cnn com wednesday es...   \n",
            "3  university degree obtain a prosperous future m...   \n",
            "4  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                      tokenized_text  \\\n",
            "0  ['ounce', 'feather', 'bowl', 'hummingbird', 'o...   \n",
            "1  ['wulvob', 'get', 'your', 'medircations', 'onl...   \n",
            "2  ['computer', 'connection', 'from', 'cnn', 'com...   \n",
            "3  ['university', 'degree', 'obtain', 'a', 'prosp...   \n",
            "4  ['thanks', 'for', 'all', 'your', 'answers', 'g...   \n",
            "\n",
            "                                     filtered_tokens  \\\n",
            "0  ['ounce', 'feather', 'bowl', 'hummingbird', 'o...   \n",
            "1  ['wulvob', 'get', 'medircations', 'online', 'q...   \n",
            "2  ['computer', 'connection', 'cnn', 'com', 'wedn...   \n",
            "3  ['university', 'degree', 'obtain', 'prosperous...   \n",
            "4  ['thanks', 'answers', 'guys', 'know', 'checked...   \n",
            "\n",
            "                                     lemmatized_text  \n",
            "0  ['ounce', 'feather', 'bowl', 'hummingbird', 'o...  \n",
            "1  ['wulvob', 'get', 'medircation', 'online', 'qn...  \n",
            "2  ['computer', 'connection', 'cnn', 'com', 'wedn...  \n",
            "3  ['university', 'degree', 'obtain', 'prosperous...  \n",
            "4  ['thank', 'answer', 'guy', 'know', 'check', 'r...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zamiana ciągów znaków na listę słów"
      ],
      "metadata": {
        "id": "lpmIQX97GEox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "data_set['lemmatized_text'] = data_set['lemmatized_text'].apply(ast.literal_eval)\n",
        "print(data_set.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohI_1nT2GHds",
        "outputId": "15eb23c7-f66e-4e4a-d12e-e812f2a4289a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                               text  \\\n",
            "0      1  ounce feather bowl hummingbird opec moment ala...   \n",
            "1      1  wulvob get your medircations online qnb ikud v...   \n",
            "2      0   computer connection from cnn com wednesday es...   \n",
            "3      1  university degree obtain a prosperous future m...   \n",
            "4      0  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                       filtered_text  \\\n",
            "0  ounce feather bowl hummingbird opec moment ala...   \n",
            "1  wulvob get your medircations online qnb ikud v...   \n",
            "2   computer connection from cnn com wednesday es...   \n",
            "3  university degree obtain a prosperous future m...   \n",
            "4  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                     normalized_text  \\\n",
            "0  ounce feather bowl hummingbird opec moment ala...   \n",
            "1  wulvob get your medircations online qnb ikud v...   \n",
            "2   computer connection from cnn com wednesday es...   \n",
            "3  university degree obtain a prosperous future m...   \n",
            "4  thanks for all your answers guys i know i shou...   \n",
            "\n",
            "                                      tokenized_text  \\\n",
            "0  ['ounce', 'feather', 'bowl', 'hummingbird', 'o...   \n",
            "1  ['wulvob', 'get', 'your', 'medircations', 'onl...   \n",
            "2  ['computer', 'connection', 'from', 'cnn', 'com...   \n",
            "3  ['university', 'degree', 'obtain', 'a', 'prosp...   \n",
            "4  ['thanks', 'for', 'all', 'your', 'answers', 'g...   \n",
            "\n",
            "                                     filtered_tokens  \\\n",
            "0  ['ounce', 'feather', 'bowl', 'hummingbird', 'o...   \n",
            "1  ['wulvob', 'get', 'medircations', 'online', 'q...   \n",
            "2  ['computer', 'connection', 'cnn', 'com', 'wedn...   \n",
            "3  ['university', 'degree', 'obtain', 'prosperous...   \n",
            "4  ['thanks', 'answers', 'guys', 'know', 'checked...   \n",
            "\n",
            "                                     lemmatized_text  \n",
            "0  [ounce, feather, bowl, hummingbird, opec, mome...  \n",
            "1  [wulvob, get, medircation, online, qnb, ikud, ...  \n",
            "2  [computer, connection, cnn, com, wednesday, es...  \n",
            "3  [university, degree, obtain, prosperous, futur...  \n",
            "4  [thank, answer, guy, know, check, rsync, manua...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pobranie pretrenowanych wektorów GloVe (niestety nie ma tutaj dedykowanego pakietu tak jak w przypadku word2vec)"
      ],
      "metadata": {
        "id": "icU3lHnmMMRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZEF88FrMQwQ",
        "outputId": "f22f49c7-3f32-4fef-d151-aa2ce0f9063f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-13 17:05:17--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-05-13 17:05:17--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-05-13 17:05:18--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2024-05-13 17:07:57 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konwersja formatu GloVe do formatu Word2Vec, który jest obsługiwany przez gensim"
      ],
      "metadata": {
        "id": "O9cHe8DaS8vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_input_file = '/content/glove.6B.100d.txt'\n",
        "word2vec_output_file = '/content/glove.6B.100d.txt.word2vec'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ckSg4PbP6AL",
        "outputId": "17d7022d-ae79-45b9-f132-8d8f1b98c820"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-89b2db1e34d3>:5: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
            "  glove2word2vec(glove_input_file, word2vec_output_file)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Załadowanie skonwertowanych wektorów do Gensim, dzięki temu mamy teraz gotowy model"
      ],
      "metadata": {
        "id": "oJVT7PElTFPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n"
      ],
      "metadata": {
        "id": "l0hHwSDCQoMG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zapisanie modelu w folderze"
      ],
      "metadata": {
        "id": "4jNCs4kTR0Ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/My Drive/data_sety/word_models/glove_model.model'\n",
        "model.save(model_path)\n"
      ],
      "metadata": {
        "id": "9o_iBvhkRGUB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Osadzanie tekstów w całym zbiorze danych"
      ],
      "metadata": {
        "id": "2hyh0IunSIMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def document_glove_embedding(doc, model):\n",
        "    vectors = [model[word] for word in doc if word in model]\n",
        "\n",
        "    if len(vectors) == 0:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "glove_embeddings = np.array([document_glove_embedding(doc, model) for doc in data_set['lemmatized_text']])\n"
      ],
      "metadata": {
        "id": "NaQsS2dsRNKe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizacja wektorów osadzeń do normy euklidesowej - Dzięki temu różnice w długości wektorów nie wpłyną na wyniki algorytmów klasteryzacji\n",
        "\n",
        "Po normalizacji, punkty są skalowane w taki sposób, by ich odległość od początku układu współrzędnych wynosiła 1."
      ],
      "metadata": {
        "id": "uMDrwr87Qn8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "normalized_embeddings = normalize(glove_embeddings, norm='l2', axis=1)\n",
        "\n",
        "glove_embeddings_df = pd.DataFrame(normalized_embeddings)"
      ],
      "metadata": {
        "id": "ZdtApV9sSJRH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zapisanie zbioru gotowego do klasteryzacji"
      ],
      "metadata": {
        "id": "fMYups9ySfQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embeddings_df.to_csv('/content/drive/My Drive/data_sety/normalized_glove_embeddings.csv', index=False)\n"
      ],
      "metadata": {
        "id": "XlfICZz4SiJ-"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}